  def fit(
        self,
        X: Union[torch.tensor, np.ndarray],
        epochs: Optional[int] = None,
        warmup_epochs: Optional[int] = None,
        batch_size: Optional[int] = None,
        knn_graph: Optional[np.ndarray] = None,
        output_folder: Optional[str] = None,
        snapshot_freq: Optional[int] = None,
        print_every: Optional[int] = None,
        retain_projector: bool = False,
        dataset_val=None,
        l2_norm_eval: Optional[bool] = False,
        eval_every: Optional[int] = None,
        please: Optional[int] = 1
    ):

        self.architecture["inputdim"] = X.shape[1]
        if epochs is not None:
            self.epochs = epochs
        if warmup_epochs is not None:
            self.warmup_epochs = warmup_epochs
        if batch_size is not None:
            self.batch_size = batch_size
            self.architecture["batch_size"] = batch_size
        if output_folder is not None:
            self.output_folder = Path(output_folder)
        if self.output_folder is not None:
            self.output_folder.mkdir(parents=True, exist_ok=True)
        if snapshot_freq is not None:
            self.snapshot_freq = snapshot_freq

        self.initialize_model()
        if self.model is None:
            raise RuntimeError("model not initialized")

        if self.verbose > 1:
            if "cuda" in self.device.type:
                print(" - Using GPU")
            else:
                print(" - Using CPU")
        n_data = X.shape[0]

        if knn_graph is not None:
            self.knn_graph = knn_graph
        elif self.knn_graph is None:
             self.compute_knn(X)

        # Resuming options
        if self.resume:
            path = self.output_folder / "final_model.pth"
            if path.is_file():
                self.load(path)
                print(" * Final model found. Skipping training.")
                return
            path = self.output_folder / "latest_snapshot.pth"
            if path.is_file():
                self.load(path)
        self.model.train()

        if isinstance(X, np.ndarray):  # if data is not a tensor convert it
            X = torch.Tensor(X)
        X = X.float()
        if self.pin_memory:
            X = X.to(self.device)

        def exclude_bias_and_norm(p):
            return p.ndim == 1

        optimizer = LARS(
            self.model.parameters(),
            lr=0,
            weight_decay=1e-6,
            weight_decay_filter=exclude_bias_and_norm,
            lars_adaptation_filter=exclude_bias_and_norm,
        )

        losses = AverageMeter("Loss", ":.4e")
        batch_sampler = BatchSampler(RandomSampler(range(n_data)), batch_size=self.batch_size, drop_last=True)
        step = self.start_epoch * len(batch_sampler)
        best_eval = 0
        t0 = time()
        with get_progress_bar() as progress:
            task = (
                progress.add_task(
                    description="[green]Training TLDR", total=(len(batch_sampler) * self.epochs), info="-"
                )
                if self.verbose > 0
                else None
            )
            for epoch in range(self.start_epoch, self.epochs):
                if self.verbose > 0:
                    progress.update(task, info=f"epoch {epoch+1} (of {self.epochs})")
                for i, ind in enumerate(batch_sampler):
                    step += 1
                    if type(self.knn_graph) == dict:  # Oracle
                        ind_nn = []
                        for j in ind:
                            ind_nn.append(random.choices(self.knn_graph[j])[0])  # 第j行第一个样本j的含k近邻的列表
                            #【0】返回随机抽取的邻居的索引值；样本 j 的邻居列表中随机选择一个邻居，并将其索引添加到 ind_nn 列表中
                        y1 = X[ind, :]  # 某一行所有列    B*D
                        y2 = X[ind_nn, :]  # 选邻居    B*D
                    else:
                        if self.gaussian:  # Synthetic neighbors
                            y1 = X[ind, :]
                            #y1=y1 = y1.to(self.device)
                            y2 = y1 + (torch.std(y1) ** 0.5) * torch.randn(y1.shape).to(self.device) * 0.1
                        else:  # Randomly select m neighbors as training pair(s)
                            y1 = X[ind, :]
                            ind_nn = np.random.randint(self.n_neighbors, size=self.batch_size)
                            y2 = X[self.knn_graph[ind, ind_nn], :]

                    if not self.pin_memory:
                        y1 = y1.to(self.device)
                        y2 = y2.to(self.device)

                    lr = adjust_learning_rate(
                        self.epochs,
                        optimizer,
                        n_data,
                        step,
                        self.learning_rate,
                        self.batch_size,
                        self.warmup_epochs,
                    )
                    optimizer.zero_grad()
                    loss = self.model.match(y1, y2).mean()
                    losses.update(loss.item(), y1.size(0))
                    loss.mean().backward()
                    optimizer.step()
                    if print_every and step % print_every == 0:
                        if self.verbose > 1:
                            progress.console.print(f" * {losses}, LR = {lr:.5f}")
                        if self.writer:
                            self.writer.add_scalar(
                                f'n{self.architecture["n_components"]}/train/loss',
                                losses.val,
                                epoch + (i / len(batch_sampler)),
                            )
                    if self.verbose > 0:
                        progress.update(task, advance=1)
                checkpoint = {
                    "epoch": epoch + 1,
                    "state_dict": self._get_state_dict(),
                    "architecture": self.architecture,
                }

                if dataset_val is not None and (epoch + 1) % eval_every == 0:
                    res = self.evaluate(dataset_val, l2_norm_eval)
                    checkpoint["val"] = res
                    if self.writer:
                        self.writer.add_scalar(
                            f'n{self.architecture["n_components"]}/val/acc',
                            res,
                            epoch + 1,
                        )
                    if res > best_eval and self.output_folder and self.save_best:
                        torch.save(checkpoint, self.output_folder / "best.pth")
                        best_eval = res
                    self.model.train()

                if self.output_folder:
                    if self.snapshot_freq and (epoch + 1) % self.snapshot_freq == 0:
                        torch.save(checkpoint, self.output_folder / f"snapshot_{epoch+1}.pth")
                    torch.save(checkpoint, self.output_folder / "latest_snapshot.pth")

            if self.output_folder:
                torch.save(checkpoint, self.output_folder / "final_model.pth")
        t1 = time()
        if self.verbose > 1:
            print(" - Fit took %.2g sec" % (t1 - t0))
        if not retain_projector:
            self.remove_projector()
